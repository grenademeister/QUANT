{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e2af689",
   "metadata": {},
   "source": [
    "# AR, MA, ARMA, ARIMA: Pure NumPy/Pandas Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b72144",
   "metadata": {},
   "source": [
    "This project provides a pure NumPy and Pandas implementation of classical time series models:\n",
    "- **AR (AutoRegressive)**\n",
    "- **MA (Moving Average)**\n",
    "- **ARMA (AutoRegressive Moving Average)**\n",
    "- **ARIMA (AutoRegressive Integrated Moving Average)**\n",
    "\n",
    "The models are implemented from scratch to enhance understanding of time series dynamics and optimization without relying on external ML libraries.\n",
    "\n",
    "Written by Hyeokgi Kim, 2025. Built for education."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f586a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden helper code\n",
    "# Helper functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import ndarray\n",
    "from pandas import Series\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def acf(series: ndarray, max_lag: int) -> np.ndarray:\n",
    "    \"\"\"Return biased autocorrelation sequence up to max_lag.\"\"\"\n",
    "    n = len(series)\n",
    "    mean = series.mean()\n",
    "    var = ((series - mean) ** 2).sum() / n\n",
    "    res = np.empty(max_lag + 1)\n",
    "\n",
    "    for k in range(max_lag + 1):\n",
    "        num = np.dot(series[: n - k] - mean, series[k:] - mean) / n\n",
    "        res[k] = num / var\n",
    "    return res\n",
    "\n",
    "\n",
    "def levinson_durbin(r: ndarray, p: int) -> np.ndarray:\n",
    "    \"\"\"Solve the Yule-Walker equations via Levinson-Durbin recursion.\"\"\"\n",
    "    phi = np.zeros(p)\n",
    "    sig = r[0]\n",
    "\n",
    "    for k in range(1, p + 1):\n",
    "        acc = r[k] - sum(phi[j - 1] * r[k - j] for j in range(1, k))\n",
    "        gamma = acc / sig\n",
    "\n",
    "        phi_prev = phi.copy()\n",
    "        phi[k - 1] = gamma\n",
    "        for j in range(1, k):\n",
    "            phi[j - 1] = phi_prev[j - 1] - gamma * phi_prev[k - j - 1]\n",
    "\n",
    "        sig *= 1.0 - gamma**2\n",
    "    return phi\n",
    "\n",
    "\n",
    "def difference(x: ndarray, d: int = 1) -> np.ndarray:\n",
    "    \"\"\"Apply d-order differencing.\"\"\"\n",
    "    for _ in range(d):\n",
    "        x = np.diff(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def optimize_gd(\n",
    "    init: ndarray,\n",
    "    loss_grad_fn,\n",
    "    lr: float = 1e-3,\n",
    "    epochs: int = 5000,\n",
    "    grad_clip: float = 1000.0,\n",
    "    tol: float = 1e-8,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generic first-order optimizer.\n",
    "    Uses gradient descent with clipping\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    init        : Initial parameter vector (copied internally).\n",
    "    loss_grad_fn: Callable(params) -> (loss, grad).\n",
    "    lr          : Learning rate.\n",
    "    epochs      : Maximum iterations.\n",
    "    grad_clip   : Gradient absolute-value clipping threshold.\n",
    "    tol         : Convergence threshold on parameter update norm.\n",
    "    \"\"\"\n",
    "    params = init.copy()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        loss, grad = loss_grad_fn(params)\n",
    "        grad = np.clip(grad, -grad_clip, grad_clip)\n",
    "        params -= lr * grad\n",
    "        step_norm = np.sqrt(np.sum((lr * grad) ** 2))\n",
    "        if _ % 1000 == 0:\n",
    "            # print(loss, grad, params)\n",
    "            continue\n",
    "        if step_norm < tol and 0:\n",
    "            # print(f\"loss = {loss}, converged\")\n",
    "            break\n",
    "    return params\n",
    "\n",
    "\n",
    "# Base model interface\n",
    "class TimeSeriesModel:\n",
    "    def fit(self, series: Series):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, series: pd.Series, steps: int = 1) -> np.ndarray:\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f479a",
   "metadata": {},
   "source": [
    "## AR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e5b4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"AR model implementation\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import ndarray\n",
    "from pandas import Series\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helper import TimeSeriesModel\n",
    "from helper import acf\n",
    "from helper import levinson_durbin\n",
    "from helper import optimize_gd\n",
    "\n",
    "\n",
    "# AR(p) model\n",
    "class ARModel(TimeSeriesModel):\n",
    "    def __init__(self, p: int):\n",
    "        self.p = p\n",
    "        self.coef = None\n",
    "\n",
    "    def fit(self, series: Series):\n",
    "        print(\"Fitting AR model...\", end=\"\")\n",
    "        r = acf(series.to_numpy(dtype=float), self.p)\n",
    "        self.coef = levinson_durbin(r, self.p)\n",
    "        print(\"Done!\")\n",
    "\n",
    "    def predict(self, series: Series, steps: int = 1) -> np.ndarray:\n",
    "        hist = series.to_numpy(dtype=float).tolist()\n",
    "        out = []\n",
    "        for _ in range(steps):\n",
    "            # TODO: compute y_hat using the last p values.\n",
    "            out.append(y_hat)\n",
    "            hist.append(y_hat)\n",
    "        return np.array(out)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # Simulate ARIMA(2, 1, 2) series\n",
    "    n = 300\n",
    "    ar_coef = np.array([0.6, -0.3])\n",
    "    ma_coef = np.array([0.5, 0.4])\n",
    "    noise = np.random.randn(n + 100)\n",
    "    x = np.zeros(n + 100)\n",
    "\n",
    "    for t in range(2, len(x)):\n",
    "        ar_part = np.dot(ar_coef, x[t - 2 : t][::-1])\n",
    "        ma_part = np.dot(ma_coef, noise[t - 2 : t][::-1])\n",
    "        x[t] = ar_part + ma_part + noise[t]\n",
    "\n",
    "    x = np.cumsum(x[100:])  # integration (d = 1)\n",
    "    ts = pd.Series(x)\n",
    "\n",
    "    # Fit model\n",
    "    ar_model = ARModel(2)\n",
    "    ar_model.fit(ts)\n",
    "\n",
    "    # Forecast next five points\n",
    "    print(\"AR: \", ar_model.predict(ts, 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256d37cf",
   "metadata": {},
   "source": [
    "\n",
    "### âœŽ Exercise\n",
    "\n",
    "Modify the `ARModel` class to log the loss every 1000 iterations during training.\n",
    "- Hint: Look inside the `optimize_gd` function.\n",
    "- Optional: Add visualization of loss over epochs.\n",
    "\n",
    "```python\n",
    "# Your code here\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17380e1",
   "metadata": {},
   "source": [
    "## MA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d57ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"MA model implementation\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helper import TimeSeriesModel\n",
    "from helper import acf\n",
    "from helper import levinson_durbin\n",
    "from helper import optimize_gd\n",
    "\n",
    "\n",
    "# MA(q) model\n",
    "class MAModel(TimeSeriesModel):\n",
    "    def __init__(self, q: int, lr: float = 1e-4, epochs: int = 10000):\n",
    "        self.q, self.lr, self.epochs = q, lr, epochs\n",
    "        self.mu = None\n",
    "        self.std = None\n",
    "        self.theta = None\n",
    "\n",
    "    def fit(self, series: pd.Series):\n",
    "        print(\"Fitting MA model...\", end=\"\")\n",
    "        x_original = series.to_numpy(dtype=float)\n",
    "        self.mu = x_original.mean()\n",
    "        self.std = x_original.std()\n",
    "        x = (x_original - self.mu) / self.std\n",
    "        n, q = len(x), self.q\n",
    "\n",
    "        def loss_grad(theta):\n",
    "            eps = np.zeros(n)\n",
    "\n",
    "            # Forward pass - compute residuals\n",
    "            for t in range(n):\n",
    "                eps[t] = x[t]\n",
    "                for j in range(min(t, q)):\n",
    "                    eps[t] -= theta[j] * eps[t - j - 1]\n",
    "\n",
    "            # Compute loss\n",
    "            loss = 0.5 * np.mean(eps**2)\n",
    "\n",
    "            # Compute gradient more stably by using finite differences\n",
    "            # for the most sensitive components\n",
    "            grad = np.zeros(q)\n",
    "            for i in range(q):\n",
    "                h = 1e-6  # Small perturbation\n",
    "                theta_plus = theta.copy()\n",
    "                theta_plus[i] += h\n",
    "\n",
    "                # Compute perturbed residuals\n",
    "                eps_plus = np.zeros(n)\n",
    "                for t in range(n):\n",
    "                    eps_plus[t] = x[t]\n",
    "                    for j in range(min(t, q)):\n",
    "                        eps_plus[t] -= theta_plus[j] * eps_plus[t - j - 1]\n",
    "\n",
    "                # Compute numerical gradient\n",
    "                # TODO: write the function to calculate loss_plus and grad\n",
    "\n",
    "            return loss, grad\n",
    "\n",
    "        # Use a smaller learning rate and tighter gradient clipping\n",
    "        self.theta = optimize_gd(\n",
    "            np.zeros(q),  # Start from zeros instead of random\n",
    "            loss_grad,\n",
    "            lr=self.lr,\n",
    "            epochs=self.epochs,\n",
    "            grad_clip=1.0,  # Much tighter gradient clipping\n",
    "        )\n",
    "        print(\"Done!\")\n",
    "\n",
    "    def predict(self, series: pd.Series, steps: int = 1) -> np.ndarray:\n",
    "        if self.theta is None:\n",
    "            raise ValueError(\"Model not fitted yet. Call fit() first.\")\n",
    "\n",
    "        x_original = series.to_numpy(dtype=float)\n",
    "        x = (x_original - self.mu) / self.std\n",
    "        eps_hist = np.zeros(len(x))\n",
    "\n",
    "        # Compute residuals on training data (used as history)\n",
    "        for t in range(len(x)):\n",
    "            eps_hist[t] = x[t]\n",
    "            for j in range(min(t, self.q)):\n",
    "                eps_hist[t] -= self.theta[j] * eps_hist[t - j - 1]\n",
    "\n",
    "        preds = []\n",
    "        for _ in range(steps):\n",
    "            pred = self.mu\n",
    "            for j in range(min(self.q, len(eps_hist))):\n",
    "                pred += self.theta[j] * self.std * eps_hist[-(j + 1)]\n",
    "            preds.append(pred)\n",
    "            eps_hist = np.append(eps_hist, 0.0)\n",
    "\n",
    "        return np.array(preds)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # Simulate ARIMA(2, 1, 2) series\n",
    "    n = 300\n",
    "    ar_coef = np.array([0.6, -0.3])\n",
    "    ma_coef = np.array([0.5, 0.4])\n",
    "    noise = np.random.randn(n + 100)\n",
    "    x = np.zeros(n + 100)\n",
    "\n",
    "    for t in range(2, len(x)):\n",
    "        ar_part = np.dot(ar_coef, x[t - 2 : t][::-1])\n",
    "        ma_part = np.dot(ma_coef, noise[t - 2 : t][::-1])\n",
    "        x[t] = ar_part + ma_part + noise[t]\n",
    "\n",
    "    x = np.cumsum(x[100:])  # integration (d = 1)\n",
    "    ts = pd.Series(x)\n",
    "\n",
    "    # Fit model\n",
    "    ma_model = MAModel(2, lr=1e-3, epochs=10000)\n",
    "    ma_model.fit(ts)\n",
    "\n",
    "    # Forecast next five points\n",
    "    print(\"MA    â†’\", ma_model.predict(ts, 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdffae0",
   "metadata": {},
   "source": [
    "\n",
    "### âœŽ Exercise\n",
    "\n",
    "Modify the `MAModel` class to log the loss every 1000 iterations during training.\n",
    "- Hint: Look inside the `optimize_gd` function.\n",
    "- Optional: Add visualization of loss over epochs.\n",
    "\n",
    "```python\n",
    "# Your code here\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853fdd8e",
   "metadata": {},
   "source": [
    "## ARMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99279cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ARMA model implementations\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helper import TimeSeriesModel\n",
    "from helper import optimize_gd\n",
    "\n",
    "\n",
    "class ARMAModel(TimeSeriesModel):\n",
    "    def __init__(self, p: int, q: int, lr: float = 1e-4, epochs: int = 10000):\n",
    "        self.p, self.q, self.lr, self.epochs = p, q, lr, epochs\n",
    "        self.ar_coef = None\n",
    "        self.ma_coef = None\n",
    "        self.mu = None\n",
    "        self.std = None\n",
    "\n",
    "    def fit(self, series: pd.Series):\n",
    "        print(\"Fitting ARMA model...\", end=\"\")\n",
    "        x_original = series.to_numpy(dtype=float)\n",
    "        self.mu = x_original.mean()\n",
    "        self.std = x_original.std()\n",
    "        x = (x_original - self.mu) / self.std\n",
    "        n, p, q = len(x), self.p, self.q\n",
    "\n",
    "        def loss_grad(params):\n",
    "            eps = np.zeros(n)\n",
    "            ar_params = params[:p]\n",
    "            ma_params = params[p:]\n",
    "\n",
    "            # Compute residuals\n",
    "            for t in range(n):\n",
    "                eps[t] = x[t]\n",
    "                for j in range(min(t, p)):\n",
    "                    eps[t] -= ar_params[j] * x[t - j - 1]\n",
    "                for j in range(min(t, q)):\n",
    "                    eps[t] -= ma_params[j] * eps[t - j - 1]\n",
    "\n",
    "            # Compute loss\n",
    "            loss = 0.5 * np.mean(eps**2)\n",
    "\n",
    "            # Compute gradients - finite difference\n",
    "            grad = np.zeros(p + q)\n",
    "            # ar params\n",
    "            for i in range(p):\n",
    "                h = 1e-6\n",
    "                params_plus = params.copy()\n",
    "                params_plus[i] += h\n",
    "                ar_plus = params_plus[:p]\n",
    "                ma_plus = params_plus[p:]\n",
    "\n",
    "                eps_plus = np.zeros(n)\n",
    "                for t in range(n):\n",
    "                    eps_plus[t] = x[t]\n",
    "                    for j in range(min(t, p)):\n",
    "                        eps_plus[t] -= ar_plus[j] * x[t - j - 1]\n",
    "                    for j in range(min(t, q)):\n",
    "                        eps_plus[t] -= ma_plus[j] * eps_plus[t - j - 1]\n",
    "\n",
    "                loss_plus = 0.5 * np.mean(eps_plus**2)\n",
    "                grad[i] = (loss_plus - loss) / h\n",
    "\n",
    "            # ma params\n",
    "            for i in range(q):\n",
    "                h = 1e-6\n",
    "                params_plus = params.copy()\n",
    "                params_plus[p + i] += h\n",
    "                ar_plus = params_plus[:p]\n",
    "                ma_plus = params_plus[p:]\n",
    "\n",
    "                eps_plus = np.zeros(n)\n",
    "                for t in range(n):\n",
    "                    eps_plus[t] = x[t]\n",
    "                    for j in range(min(t, p)):\n",
    "                        eps_plus[t] -= ar_plus[j] * x[t - j - 1]\n",
    "                    for j in range(min(t, q)):\n",
    "                        eps_plus[t] -= ma_plus[j] * eps_plus[t - j - 1]\n",
    "\n",
    "                loss_plus = 0.5 * np.mean(eps_plus**2)\n",
    "                grad[p + i] = (loss_plus - loss) / h\n",
    "            return loss, grad\n",
    "\n",
    "        params = optimize_gd(\n",
    "            np.zeros(p + q),\n",
    "            loss_grad,\n",
    "            lr=self.lr,\n",
    "            epochs=self.epochs,\n",
    "            grad_clip=1.0,\n",
    "        )\n",
    "        self.ar_coef = params[:p]\n",
    "        self.ma_coef = params[p:]\n",
    "        print(\"Done!\")\n",
    "\n",
    "    def predict(self, series: pd.Series, steps: int = 1) -> np.ndarray:\n",
    "        if self.ar_coef is None or self.ma_coef is None:\n",
    "            raise ValueError(\"Model not fitted yet. Call fit() first.\")\n",
    "\n",
    "        x_original = series.to_numpy(dtype=float)\n",
    "        x = (x_original - self.mu) / self.std\n",
    "        n = len(x)\n",
    "        eps = np.zeros(n)\n",
    "\n",
    "        # Compute residuals\n",
    "        for t in range(n):\n",
    "            eps[t] = x[t]\n",
    "            for j in range(min(t, self.p)):\n",
    "                eps[t] -= self.ar_coef[j] * x[t - j - 1]\n",
    "            for j in range(min(t, self.q)):\n",
    "                eps[t] -= self.ma_coef[j] * eps[t - j - 1]\n",
    "\n",
    "        preds = []\n",
    "        forecast_x = np.append(x, np.zeros(steps))\n",
    "        forecast_eps = np.append(eps, np.zeros(steps))\n",
    "\n",
    "        for t in range(n, n + steps):\n",
    "            forecast = self.mu\n",
    "            for j in range(self.p):\n",
    "                if t - j - 1 >= 0:\n",
    "                    forecast += self.ar_coef[j] * self.std * forecast_x[t - j - 1]\n",
    "            for j in range(self.q):\n",
    "                if t - j - 1 >= 0:\n",
    "                    forecast += self.ma_coef[j] * self.std * forecast_eps[t - j - 1]\n",
    "\n",
    "            preds.append(forecast)\n",
    "            forecast_x[t] = (forecast - self.mu) / self.std\n",
    "        return np.array(preds)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # Simulate ARIMA(2, 1, 2) series\n",
    "    n = 300\n",
    "    ar_coef = np.array([0.6, -0.3])\n",
    "    ma_coef = np.array([0.5, 0.4])\n",
    "    noise = np.random.randn(n + 100)\n",
    "    x = np.zeros(n + 100)\n",
    "\n",
    "    for t in range(2, len(x)):\n",
    "        ar_part = np.dot(ar_coef, x[t - 2 : t][::-1])\n",
    "        ma_part = np.dot(ma_coef, noise[t - 2 : t][::-1])\n",
    "        x[t] = ar_part + ma_part + noise[t]\n",
    "\n",
    "    x = np.cumsum(x[100:])  # integration (d = 1)\n",
    "    ts = pd.Series(x)\n",
    "\n",
    "    # Fit models\n",
    "    arma_model = ARMAModel(2, 2, lr=1e-2, epochs=5000)\n",
    "    arma_model.fit(ts.diff().dropna())  # Manually difference for ARMA\n",
    "\n",
    "    # Forecast next five points\n",
    "    print(\"ARMA coeffs: \", arma_model.ar_coef, arma_model.ma_coef)\n",
    "    print(\"ARMA predictions: \", arma_model.predict(ts.diff().dropna(), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae3673f",
   "metadata": {},
   "source": [
    "\n",
    "### âœŽ Exercise\n",
    "\n",
    "Modify the `ARMAModel` class to log the loss every 100 iterations during training.\n",
    "And try to plot it.\n",
    "- Hint: Look inside the `optimize_gd` function.\n",
    "- Optional: Add visualization of loss over epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeea834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4c5bd5",
   "metadata": {},
   "source": [
    "## ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117a4dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ARIMA model implementations\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helper import TimeSeriesModel\n",
    "from helper import optimize_gd\n",
    "from arma import ARMAModel\n",
    "\n",
    "\n",
    "class ARIMAModel(TimeSeriesModel):\n",
    "    def __init__(self, p: int, d: int, q: int, lr: float = 1e-4, epochs: int = 10000):\n",
    "        self.p = p  # AR order\n",
    "        self.d = d  # Differencing order\n",
    "        self.q = q  # MA order\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.arma_model = ARMAModel(p, q, lr, epochs)\n",
    "        self.original_series = None\n",
    "\n",
    "    def fit(self, series: pd.Series):\n",
    "        print(f\"Fitting ARIMA({self.p},{self.d},{self.q}) model...\", end=\"\")\n",
    "        self.original_series = series.copy()\n",
    "\n",
    "        # Apply d-order differencing\n",
    "        differenced_series = series.copy()\n",
    "        # TODO: apply d-order differencing.\n",
    "        # you may use helper.difference\n",
    "\n",
    "        # Fit ARMA model on differenced series\n",
    "        self.arma_model.fit(differenced_series)\n",
    "        print(\"ARIMA model fitted!\")\n",
    "\n",
    "    def predict(self, series: pd.Series, steps: int = 1) -> np.ndarray:\n",
    "        if self.arma_model.ar_coef is None:\n",
    "            raise ValueError(\"Model not fitted yet. Call fit() first.\")\n",
    "\n",
    "        latest_series = series.copy()\n",
    "        differenced_series = latest_series.copy()\n",
    "        # TODO: apply d-order differencing.\n",
    "        # just write the same code from above\n",
    "\n",
    "        diff_forecasts = self.arma_model.predict(differenced_series, steps)\n",
    "\n",
    "        # Undo differencing (integration)\n",
    "        if self.d == 0:\n",
    "            return diff_forecasts\n",
    "        last_values = [latest_series.iloc[-i - 1] for i in range(self.d)]\n",
    "\n",
    "        forecasts = np.zeros(steps)\n",
    "        for i in range(steps):\n",
    "            value = diff_forecasts[i]\n",
    "            for j in range(self.d):\n",
    "                value += last_values[j]\n",
    "            forecasts[i] = value\n",
    "            for j in range(self.d - 1, 0, -1):\n",
    "                last_values[j] = last_values[j - 1]\n",
    "            last_values[0] = forecasts[i]\n",
    "\n",
    "        return forecasts\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # Simulate ARIMA(2, 1, 2) series\n",
    "    n = 300\n",
    "    ar_coef = np.array([0.6, -0.3])\n",
    "    ma_coef = np.array([0.5, 0.4])\n",
    "    noise = np.random.randn(n + 100)\n",
    "    x = np.zeros(n + 100)\n",
    "\n",
    "    for t in range(2, len(x)):\n",
    "        ar_part = np.dot(ar_coef, x[t - 2 : t][::-1])\n",
    "        ma_part = np.dot(ma_coef, noise[t - 2 : t][::-1])\n",
    "        x[t] = ar_part + ma_part + noise[t]\n",
    "\n",
    "    x = np.cumsum(x[100:])  # integration (d = 1)\n",
    "    ts = pd.Series(x)\n",
    "\n",
    "    # Fit models\n",
    "    arima_model = ARIMAModel(2, 1, 2, lr=1e-2, epochs=5000)\n",
    "    arima_model.fit(ts)\n",
    "\n",
    "    # Forecast next five points\n",
    "    print(\"ARIMA coeffs: \", arima_model.ar_coef, arima_model.ma_coef)\n",
    "    print(\"ARIMA predictions: \", arima_model.predict(ts, 5))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
